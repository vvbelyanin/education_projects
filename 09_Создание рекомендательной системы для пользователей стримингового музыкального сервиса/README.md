**Рекомендательные системы. Создание рекомендательной системы для пользователей стримингового музыкального сервиса**  

Для удобства пользователей популярного стримингового сервиса с большим каталогом нужна эффективная система рекомендаций музыкальных треков для прослушивания на основе пользовательских вкусов и предпочтений.  
На основе данных взаимодействий ~1,4 млн пользователей с 1 млн треков необходимо построить пайплайн для расчёта персональных рекомендаций, а также разработать сервис рекомендаций.  

Рабочий процесс и инструменты      
| # | Описание | Инструменты/Ключевые слова |
|:----:|:---------------------------|:-----------------------------------------------------------|
| 1 | Первичная подготовка данных | `pandas` `S3`|
| 2 | Анализ данных и их подготовка | `matplotlib` `numpy` |
| 3 | Офлайн-рекомендации | `sklearn` ` implicit.als` `CatBoostClassifier`|
| 4 | Развертывание онлайн-сервиса | `FastAPI` `uvicorn`|
| 5 | Тестирование сервиса | `unittest`|


# Проект. Создание рекомендательной системы (2 части)

##### Описание задачи
Создание эффективной системы персональных рекомендаций для популярного стримингового сервиса с большим каталогом — более 70 млн треков.  
Для удобства пользователей такая система должна предлагать музыкальные треки для прослушивания на основе их вкусов и предпочтений.  
  
##### Задача машинного обучения  
На основе данных взаимодействий ~1,4 млн пользователей с 1 млн треков необходимо построить пайплайн для расчёта персональных рекомендаций, а также разработать сервис рекомендаций.  
  
##### Результат работы
Набор скриптов в репозитории для расчета персональных рекомендаций и для запуска соответствующего сервиса для их получения.

В файле [Instructions.md](./Instructions.md) содержатся общие технические инструкции.
  
#### Часть 1 (этапы 1, 2, 3).
Описание, реализация и выводы см. в Jupyter notebook:  
[recommendations.ipynb](./recommendations.ipynb).

#### Часть 2 (этап 4). Сервис рекомендаций.
Краткое описание и выводы приводятся ниже.  

Сервис реализован с помощью скриптов:  
[recommendation_service.py](./recommendation_service.py),  
[test_service.py](./test_service.py).  
Последний генерирует лог [test_service.log](./test_service.log).  
    
Сервис рекомендаций реализован на базе фреймворка FastAPI, который обеспечивает интерфейс API по протоколу HTTP, обрабатывая входящие запросы.  
Низкоуровневый сервис обеспечивает ASGI-сервер uvicorn, для аннотации и валидации типов используются библиотеки typing и pydantic.  
Для сопровождения запуска и завершения работы сервиса используется контекст-менеджер asynccontextmanager.  
Итак, FastAPI-микросервис выдает следующие рекомендации:
- для пользователей с новым идентификатором - k (по умолчанию k=25) популярных треков
- для пользователей только с онлайн-историей взаимодействий - k (по умолчанию k=25) треков, максимально похожих на те, которые встречались в истории
- пользователям, у которых есть офлайн-рекомендации в датасете events - k (по умолчанию k=25) треков, рекомендованных алгоритмом ALS
- пользователям, у которых есть офлайн- и онлайн-истории, выдает смешанные рекомендации
  
Смешанные рекомендации формируются следующим образом, реализованным методом get() класса Recommendations():
- формируются списки offline_list, online_list максимальной длины
- функция blended_list() может смешивать заданные списки двумя способами:
  - 'strict' - из вершины каждого списка (отсортированного по убыванию score) строго по очереди берутся элементы и добавляются в итоговый список
  - 'probability' - из вершины каждого списка по очереди берутся элементы, но добавляются только с заданной вероятностью (по умолчанию вероятность = 0.5). Таким образом можно менять веса рекомендаций, основанных на истории взаимодействий и на похожести треков
- если какой-то из списков короче, то в итоговый список добавляются все оставшиеся элементы более длинного списка
- если итоговый список пустой, то выдаются рекомендации по умолчанию - топ популярных треков
  
Сервис реализован в виде класса Recommendations():
- в классе ведется статистика выдачи трех типов рекомендаций: 'personal', 'similar', 'default'; вывод статистики осуществляется методом stats()
- метод load() загружает датасеты из подкаталога /parquet в начале работы сервиса
- метод get() непосредственно выдает рекомендации 
- метод get_similar_items() возвращает похожие треки для треков из заданного списка
- метод update_user_events() служит для добавления событий к онлайн-истории пользователя
- наконец, метод get_user_history() выводит онлайн-историю для заданного пользователя
  
Тестирование сервиса производится отдельным скриптом [test_service.py](./test_service.py), который включает в себя следующие тесты:  
- каждый эндпоинт проходит проверку статуса запроса, а также типа (list, dict) и размера возвращаемых данных
- тест корневого эндпоинта "/"
- тест выдачи популярных треков "/top_popular/k" (k - размер списка выдачи, необязательный параметр)
- тест выдачи похожих треков "/similar/k"
- тест выдачи онлайн-истории "/history/user_id" для несуществующего пользователя
- тест добавления истории взаимодействий "/history/user_id" для заданного пользователя
- тест выдачи онлайн-истории "/history/user_id" для существующего пользователя
- тест выдачи рекомендаций для пользователя без офлайн- и без онлайн-истории (по умолчанию - топ популярных треков)
- тест выдачи рекомендаций для пользователя без офлайн-, но с онлайн-историей (похожие треки)
- тест выдачи рекомендаций для пользователя с офлайн-, но без онлайн-истории (персональные ALS)
- тест выдачи рекомендаций для пользователя с офлайн- и с онлайн-историей (смешанные персональные ALS и похожие треки)
- тест выдачи статистики запросов  

Скрипт записывает вывод тестов в файл [test_service.log](./test_service.log) и по окончании работы выводит его в терминал.
